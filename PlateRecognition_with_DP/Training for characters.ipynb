{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Training for characters.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1v50DchPblmHRizj2sCxglfRfSnVOCLVB","authorship_tag":"ABX9TyPL/kCYVjnXtfNyeYjVeZLK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"FC5CwZuEwJIK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"71e7f22e-2d54-4e56-d6f3-912cb637873a"},"source":["from google.colab import drive\n","drive.mount(\"\\content\\mydrive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n","\n","Enter your authorization code:\n","4/1AY0e-g74__bbY7UQUFbdY_IPqTEoWsYw2ke4XZIvCNfjuhgawBtMLZ3KZIM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CGW4zNY5uaBf"},"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'   #disattiva tutti i warning\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications import MobileNetV2\n","from keras.layers import AveragePooling2D\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import img_to_array\n","from keras.preprocessing.image import load_img\n","from keras.utils import to_categorical\n","from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n","from keras.models import model_from_json\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","import glob\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8-7UXcmVu_ye"},"source":["### Visualize datasetÂ¶"]},{"cell_type":"code","metadata":{"id":"gOx4EqCbu-cA"},"source":["dataset_paths = glob.glob(\"/content/drive/MyDrive/PlateRecognition_with_DP/dataset_characters/**/*.jpg\")\n","\n","cols=4\n","rows=3\n","fig = plt.figure(figsize=(10,8))\n","plt.rcParams.update({\"font.size\":14})   #modifica i valori di dafault della libreria\n","grid = gridspec.GridSpec(ncols=cols,nrows=rows,figure=fig)\n","\n","# crea una lista random di immagini da mostrare\n","np.random.seed(45)\n","rand = np.random.randint(0,len(dataset_paths),size=(cols*rows))\n","\n","# Plot image\n","for i in range(cols*rows):\n","    fig.add_subplot(grid[i])\n","    image = load_img(dataset_paths[rand[i]])\n","    label = dataset_paths[rand[i]].split(os.path.sep)[-2]\n","    plt.title('\"{:s}\"'.format(label))\n","    plt.axis(False)\n","    plt.imshow(image)\n","\n","plt.savefig(\"Visualize_dataset.jpg\",dpi=300)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yfl_9GibvJo-"},"source":["\n","###pre-processing delle immagini"]},{"cell_type":"code","metadata":{"id":"kTHkNefFvISu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620215132339,"user_tz":-120,"elapsed":7307318,"user":{"displayName":"Francesco Ottata","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgkYxIcfT4eMqhKLP6EQiQHLqW_kp_tVTBDww4IYg=s64","userId":"12520556861045236312"}},"outputId":"da276455-fc58-4ba2-9748-f77ce4b2ad3e"},"source":["X=[]\n","labels=[]\n","\n","with tf.device(\"/GPU:0\"):\n"," for image_path in dataset_paths:\n","  label = image_path.split(os.path.sep)[-2]\n","  image=load_img(image_path,target_size=(80,80))\n","  image=img_to_array(image)\n","\n","  X.append(image)\n","  labels.append(label)\n","\n"," X = np.array(X,dtype=\"float16\")\n"," labels = np.array(labels)\n","\n","print(\"[INFO] Ho trovato {:d} immagini relative a {:d} classi\".format(len(X),len(set(labels))))\n","\n","\n","# Codifico le etichette \n","lb = LabelEncoder()\n","lb.fit(labels)\n","labels = lb.transform(labels)\n","y = to_categorical(labels)\n","\n","# salva le etichette in un file \n","#if not os.path.exists(/content/drive/MyDrive/PlateRecognition_with_DP/license_character_classes.npy):\n","np.save('license_character_classes.npy', lb.classes_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] Ho trovato 33387 immagini relative a 36 classi\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wzJ7EKn3vikT"},"source":["# split 10% of data as validation set\n","(trainX, testX, trainY, testY) = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKk_7w0rvoJ_"},"source":["# data augumentation\n","image_gen = ImageDataGenerator(rotation_range=10,\n","                              width_shift_range=0.1,\n","                              height_shift_range=0.1,\n","                              shear_range=0.1,\n","                              zoom_range=0.1,\n","                              fill_mode=\"nearest\"\n","                              )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fpumCToNvpHJ"},"source":["### Creazione modello con  pesi pre-addrestrati"]},{"cell_type":"code","metadata":{"id":"VZgt7vttvs3_"},"source":["def create_model(lr=1e-4,decay=1e-4/25, training=False,output_shape=y.shape[1]):\n","    baseModel = MobileNetV2(weights=\"imagenet\", \n","                            include_top=False,\n","                            input_tensor=Input(shape=(80, 80, 3)))\n","\n","    headModel = baseModel.output\n","    headModel = AveragePooling2D(pool_size=(3, 3))(headModel)\n","    headModel = Flatten(name=\"flatten\")(headModel)\n","    headModel = Dense(128, activation=\"relu\")(headModel)\n","    headModel = Dropout(0.5)(headModel)\n","    headModel = Dense(output_shape, activation=\"softmax\")(headModel)\n","    model = Model(inputs=baseModel.input, outputs=headModel)\n","    \n","    if training:\n","        for layer in baseModel.layers:\n","            layer.trainable = True\n","        # compila il modello\n","        optimizer = Adam(lr=lr, decay = decay)\n","        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,metrics=[\"accuracy\"])    \n","        \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOnQuZrDvvzG"},"source":["# initilaize initial hyperparameter\n","INIT_LR = 1e-4\n","EPOCHS = 30\n","\n","model = create_model(lr=INIT_LR, decay=INIT_LR/EPOCHS,training=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LJVRnsOpv1Mp"},"source":["### Train del modello"]},{"cell_type":"code","metadata":{"id":"xInG2brhvzSC"},"source":["BATCH_SIZE = 64\n","\n","my_checkpointer = [\n","                ReduceLROnPlateau(monitor ='val_loss', factor=0.5, patience=5,verbose = 1),\n","                EarlyStopping(monitor='val_loss', patience=5, verbose=1),\n","                ModelCheckpoint(filepath=\"License_character_recognition.h5\", verbose=1, save_weights_only=True)\n","                ]\n","with tf.device(\"/GPU:0\"):\n"," result = model.fit(image_gen.flow(trainX, trainY, batch_size=BATCH_SIZE), #applica in tempo reale la data augmentation \n","                   steps_per_epoch=len(trainX) // BATCH_SIZE, \n","                   validation_data=(testX, testY), \n","                   verbose = 1,\n","                   validation_steps=len(testX) // BATCH_SIZE, \n","                   epochs=EPOCHS, callbacks=my_checkpointer)\n","\n","fig = plt.figure(figsize=(14,5))\n","grid=gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\n","fig.add_subplot(grid[0])\n","plt.plot(result.history['accuracy'], label='training accuracy')\n","plt.plot(result.history['val_accuracy'], label='val accuracy')\n","plt.title('Accuracy')\n","plt.xlabel('epochs')\n","plt.ylabel('accuracy')\n","plt.legend()\n","\n","fig.add_subplot(grid[1])\n","plt.plot(result.history['loss'], label='training loss')\n","plt.plot(result.history['val_loss'], label='val loss')\n","plt.title('Loss')\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.legend()\n","\n","plt.savefig(\"Training_result.jpg\",dpi=300)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twk3FWWRwDdB"},"source":["# salva il modello come un json file\n","os.chan\n","model_json = model.to_json()\n","with open(\"MobileNets_character_recognition.json\", \"w\") as json_file:\n","  json_file.write(model_json)"],"execution_count":null,"outputs":[]}]}